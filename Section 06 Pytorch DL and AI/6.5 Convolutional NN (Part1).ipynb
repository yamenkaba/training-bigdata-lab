{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "A convolutional neural network (CNN) is a feedforward neural network with layers used as filters to the input image by sliding a filter across small sections of the image to produce an activation map. Recall that regular feedforward networks are made up of individual computation units or neurons, and the training process requires backpropagation to learn their weights and biases. Each computation unit combines the input with weights using a dot product and passes it to a nonlinear function that produces an output. This output is often used as input to the neurons\n",
    "in the next layer till we reach the output layer.\n",
    "\n",
    "CNNs are developed and centered around finding features within images with the use of a mathematical operation called convolution in at least one of their layers. In this section, we will understand how CNNs work, followed by discussion on individual parts of CNN that may be tuned, and see examples of convolutional neural networks in action.\n",
    "\n",
    "## Convolution Operation\n",
    "Each pixel in an image is not a unique data source but is dependent on the pixels around it – often portraying continuity of the same object by having similar values (similar color or intensity), or abrupt boundary of object by sharp difference in the values in terms of color or brightness. Convolution allows us to capture such features through a set of predefined kernels that operate on the images.\n",
    "\n",
    "Convolution is a mathematical operation in which a kernel (or filter) is applied to a part of the input data (usually image) to produce an element, slid over the whole image, to produce a final modified image. Consider the matrix and the filter as shown below:\n",
    "\n",
    "![cnn-example](images/cnn-example.png)\n",
    "\n",
    "The 4x4 matrix is operated with a 2x2 filter, which leads to the filter being mapped to the top-left part of the matrix. This leads to one singular value that is saved as the output in one of the cells of the resulting matrix as shown above. The filter then slides to the right and performs a similar computation to the next part of the image shown below:\n",
    "\n",
    "![cnn-example-2](images/cnn-example-2.png)\n",
    "\n",
    "The process continues till all the values of the original matrix are filled as shown below:\n",
    "\n",
    "![cnn-example-3](images/cnn-example-3.png)\n",
    "\n",
    "As the resulting matrix is much smaller, we sometimes add padding so that the resulting image is of similar size as that of the original image. So we may instead begin with the padded matrix as shown below:\n",
    "\n",
    "![cnn-example-4](images/cnn-example-4.png)\n",
    "\n",
    "Filter essentially filters out everything that is not related to the pattern contained in the filter. We want to learn the filters to find patterns based on the given dataset. In easy words, convolution is just a sliding pattern finder. In image processing software, there are \n",
    "some standard filters that provide the common effects like sharpening, blurring, edge detection, etc. A simple example is shown below:\n",
    "\n",
    "![cnn-sharp](images/cnn-sharp.png)\n",
    "\n",
    "We can build more sophisticated filters that can be used to discover a particular type of patterns. below figure shows a filter containing a pattern (or image) of a human eye, and when a convolution operation is performed on an image with this filter, the result will contain a high value where the filter closely matches a pattern in the original image.\n",
    "\n",
    "![cnn-eye](images/cnn-eye.png)\n",
    "\n",
    "In colored images, each image is a (3xWxH) three-dimensional array where W is the width and H is the height of the image in terms of pixels. There are three channels of WxH size matrix that represent the red, green, and blue channels of the image. For such a case, the kernel also needs to be a three-channel kernel. Thus, if we had a kernel of size 3x3 in two dimensions, now we would have a kernel of size 3x3x3, where\n",
    "we apply layers of kernel in each channel of the image.\n",
    "\n",
    "![cnn-color-example](images/cnn-color-example.png)\n",
    "\n",
    "We can have more than one kernel. Each kernel will produce one two-dimensional matrix as shown below. Thus, if we use three different kernels, the result will be a three-dimensional matrix that has result of each kernel present as layers across one of the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure of a CNN\n",
    "CNNs are neural networks that leverage convolution operation in at least one of the layers. There are many popular architectures that have been proven to be effective in various image classification–related tasks. Below figure shows a simple and the most standard configuration of convolutional neural networks.\n",
    "\n",
    "![cnn-standard-conf](images/cnn-standard-conf.png)\n",
    "\n",
    "The input is a `HxWxC` shape tensor that holds the original values of image pixels. `H` and `W` represent the height and weight of the image in terms of pixels, and `C` represents the number of channels (usually three for RGB color image and one for monochromatic grayscale images). The input is connected to the convolution layer that performs convolution operation on the image with F filters. Thus, with a padding of 1 and a stride of 1 (explained in the next paragraphs), this will lead to a HxWxF size output. This is followed by an activation layer `(preferably ReLU)` that doesn’t affect the size.\n",
    "\n",
    "After convolution and activation, a pooling layer can compress the feature activation information about the image by aggregating nearby pixels and down sample the data. Max pooling can be used to pick the maximum value of each part of the image. It helps make the representation translation invariant, that is, not being affected by small changes in location of a feature in the image. Thus, HxWxF image may result in `H/2xW/2xF` sized output.\n",
    "\n",
    "At this point, we may decide to flatten this and forward to one or more arbitrary fully connected layers with C units in the output layer, where C is the number of categories the image input may be classified into. In many applications, we add multiple sets of convolution layer followed by polling layer, which can aggregate multiple features that are detected in the previous stage.\n",
    "\n",
    "### Padding and Stride\n",
    "When specifying the hyperparameters of filters in a convolution layer, we may choose a depth, stride, and padding. These decisions may have major implication in the performance and capabilities of the final model thus being generated. Depth, or the number of filters, decides how many different features within the image may be captured by the network. Each filter may learn to discover a pattern in the image, a certain kind of edges, or color combinations. While specifying this, we also specify the size of the filters.\n",
    "\n",
    "Stride defines how much the filter slides across the original image. A default stride of 1 means that the filter moves only one pixel at a time. A stride of 2 means that the filter will jump over by two steps instead and then perform the multiplication and summation operations at the next location in the image. Below figure shows the difference in the output because of change in strides.\n",
    "\n",
    "![stride](images/stride.png)\n",
    "\n",
    "Padding adds another rows and columns at the borders of the original image and puts a value of 0 in these cells. As a convolution operation combines the information from a larger part of the image, a padding of 1 with a stride of 1 would result in the output of the same size as that of the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Using CNN\n",
    "In this example, we will use another popular dataset called MNIST Fashion. MNIST Fashion attracted a lot of attention due to debate against the use of MNIST digits as many relatively simple CNN-based networks were easily able to achieve accuracies of 99% or more. Ian Goodfellow, a highly cited deep learning researcher working with Apple Inc. (as of mid-2021), made a comment on social media saying “Instead of moving on to harder datasets than MNIST, the ML community is studying it more than ever.” This led to exploration of other datasets, and Zalando ten-category clothing classification dataset soon caught public attention.\n",
    "\n",
    "![mnist-fashion](images/mnist-fashion.png)\n",
    "\n",
    "Each image in the dataset is a 28x28 pixel grayscale image, and each pixel is an integer between 0 and 255. There are 60000 items in the training set and 10000 items in the test set, each belonging to one of these categories: T-shirt/top, Trouser, Pullover, Dress, Coat, Sandal,\n",
    "Shirt, Sneaker, Bag, and Ankle boot. A small part of the dataset is shown in above figure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37c6bd7f1a9db26b7086562c17aab78d6bfc12219704eacbd062a7add86ffb6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
